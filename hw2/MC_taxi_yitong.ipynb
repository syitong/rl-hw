{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# import RidiculusTaxi\n",
    "import mytaxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(a,b):\n",
    "    return np.sqrt(np.mean((a-b)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#state:501, #action6\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Taxi-v3').unwrapped\n",
    "numS = env.observation_space.n\n",
    "numA = env.action_space.n\n",
    "print(\"#state:{}, #action{}\".format(numS, numA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_s(policy_s):\n",
    "    p = policy_s / sum(policy_s)\n",
    "    return np.random.choice(numA,p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_prediction(baseline, policy, env, num_episodes, discount_factor=1.0):\n",
    "\n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    \n",
    "    # The final value function\n",
    "    V = np.zeros(env.nS)\n",
    "    RMS = []\n",
    "    for i_episode in range(1, num_episodes + 1):\n",
    "\n",
    "        if i_episode % 1000 == 0:\n",
    "            print(\"\\rEpisode {}/{}.\".format(i_episode, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # An episode is an array of (state, action, reward) tuples\n",
    "        episode = []\n",
    "        state = env.reset()\n",
    "        done=False\n",
    "        while not done:\n",
    "#        for t in range(1000):\n",
    "            \n",
    "            action = action_s(policy[state])\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            episode.append((state, action, reward))\n",
    "#            if done:\n",
    "#                break\n",
    "            state = next_state\n",
    "\n",
    "        # Find all states the we've visited in this episode\n",
    "        states_in_episode = set([x[0] for x in episode])\n",
    "        for state in states_in_episode:\n",
    "            # Find the first occurance of the state in the episode\n",
    "            first_occurence_idx = next(i for i,x in enumerate(episode) if x[0] == state)\n",
    "            # Sum up all rewards since the first occurance\n",
    "            G = sum([x[2]*(discount_factor**i) for i,x in enumerate(episode[first_occurence_idx:])])\n",
    "            # Calculate average return for this state over all sampled episodes\n",
    "            returns_sum[state] += G\n",
    "            returns_count[state] += 1.0\n",
    "            V[state] = returns_sum[state] / returns_count[state]\n",
    "        RMS_ep = rms(baseline,V)\n",
    "        RMS.append(RMS_ep)\n",
    "\n",
    "    return np.array(RMS), V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_function(V, baseline, title=\"Value Function\"):\n",
    "    \"\"\"\n",
    "    Plots the value function as a surface plot.\n",
    "    \"\"\"\n",
    "    V_ordered = OrderedDict(sorted(V.items()))\n",
    "    \n",
    "    print('\\n')\n",
    "    print(len(V.keys()))\n",
    "    \n",
    "    v_s = np.zeros(len(V.keys()))\n",
    "    idx = 0\n",
    "    for key, val in V_ordered.items():\n",
    "        v_s[idx] = val\n",
    "        idx +=1\n",
    "\n",
    "    # print(np.sort(np.asarray(V.keys())))\n",
    "\n",
    "#     plt.plot(np.asarray(v_s), marker='o',linewidth=2)\n",
    "    plt.plot(v_s,marker='o',linestyle='None',label='mc')\n",
    "    plt.plot(baseline,marker='x',linestyle='None',label='base')\n",
    "    plt.legend([\"MC\", \"Baseline\"])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"State\", fontsize=20)\n",
    "    plt.savefig(\"mc_prediction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mc(env,baseline,runs,policy,\n",
    "        discount_factor=1,num_episodes=1000):\n",
    "    RMS = np.zeros(num_episodes)\n",
    "    V = np.zeros(env.nS)\n",
    "    for idx in range(runs):\n",
    "        RMS_run,V_run = mc_prediction(baseline,policy,env,\n",
    "            num_episodes=num_episodes,discount_factor=discount_factor)\n",
    "        RMS += RMS_run\n",
    "        V += V_run\n",
    "    RMS /= runs\n",
    "    V /= runs\n",
    "    fig = plt.figure()\n",
    "    plt.plot(RMS)\n",
    "    plt.savefig('mc-error.eps')\n",
    "    plt.close(fig)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(V,marker='o',linestyle='None',label='mc')\n",
    "    plt.plot(baseline,marker='x',linestyle='None',label='base')\n",
    "    plt.legend(loc=3)\n",
    "    plt.savefig('mc-qplot.eps')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50000/50000."
     ]
    }
   ],
   "source": [
    "# evaluate the given policy\n",
    "with open('policy','r') as fp:\n",
    "    policy = eval(fp.read())\n",
    "        \n",
    "# V_10k = mc_prediction(policy, env, num_episodes=50000)\n",
    "# plot_value_function(V_10k, title=\"100,000 Epesodes\")\n",
    "baseline = np.load('baseline.npy')\n",
    "# plot_value_function(V_10k, baseline, title=\"MC_prediction\")\n",
    "plot_mc(env,baseline,runs=1,policy=policy,num_episodes=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
